---
title: "Yihan - DSE_Project"
author: "YH"
date: "2025-02-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(readr)
library(readxl)
library(stringr)
library(lubridate)
library(tidyverse)
library(dplyr)
library(dynlm)
library(vars)
library(tseries)
library(forecast)
library(sf)
library(jsonlite)
library(geosphere)
library(FactoMineR)

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
library(httr)
library(jsonlite)

# API endpoint and API key
api_url <- "http://datamall2.mytransport.sg/ltaodataservice/BusStops"
api_key <- "oS8RIpj+SBK/tB+Hv5CHVg==" 

# Initialize variables
skip <- 0
top <- 50  # Number of records per request
all_bus_stops <- data.frame()


while (TRUE) {
  # Send GET request with pagination parameters
  response <- GET(
    api_url,
    add_headers(AccountKey = api_key),
    query = list(`$skip` = skip, `$top` = top)
  )
  
  # Check if the request was successful
  if (http_status(response)$category != "Success") {
    print(paste("API request failed with status:", http_status(response)$message))
    break
  }
  
  # Extract and parse the JSON data
  response_content <- content(response, "text")
  json_data <- fromJSON(response_content)
  
  # Append the data to the all_bus_stops data frame
  current_bus_stops <- as.data.frame(json_data$value)
  all_bus_stops <- rbind(all_bus_stops, current_bus_stops)
  
  # Check if there are more records
  if (nrow(current_bus_stops) < top) {
    break  # Exit the loop if no more records are returned
  }
  
  # Update the skip value for the next request
  skip <- skip + top
}

# Print the final data frame
print(all_bus_stops)

# Save the data to a CSV file
write.csv(all_bus_stops, "bus_stops.csv", row.names = FALSE)

```
```{r}
all_bus_stops_cleaned <- distinct(all_bus_stops)
```


```{r}
coords <- read.csv("../data/street_name_planning_area.csv")

calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
# Define the distance threshold (in meters)
distance_threshold <- 500

# Initialize a list to store results
results <- list()

# Loop through each street
for (i in 1:nrow(coords)) {
  street_name <- coords$Street_name[i]
  street_lat <- coords$latitude[i]
  street_lon <- coords$longitude[i]
  
  # Loop through each bus stop
  for (j in 1:nrow(all_bus_stops_cleaned)) {
    bus_stop_code <- all_bus_stops_cleaned$BusStopCode[j]
    bus_stop_lat <- all_bus_stops_cleaned$Latitude[j]
    bus_stop_lon <- all_bus_stops_cleaned$Longitude[j]
    
    # Calculate the distance
    distance <- calculate_distance(street_lat, street_lon, bus_stop_lat, bus_stop_lon)
    
    # Check if the distance is below the threshold
    if (distance <= distance_threshold) {
      results <- rbind(results, data.frame(
        StreetName = street_name,
        BusStopCode = bus_stop_code,
        Distance = distance
      ))
    }
  }
}

# Convert the results to a data frame
results_df <- as.data.frame(results)

# Print the results
print(results_df)
```
```{r}
number_of_bus_stops_near_street <- results_df %>%
  group_by(StreetName) %>%
  summarise(number_of_bus_stops=n(), average_dist=sum(Distance)/n())
```

```{r}
write.csv(number_of_bus_stops_near_street, "../data/number_of_bus_stops_near_street.csv")
```

```{r}
total_find_missing <- left_join(coords,number_of_bus_stops_near_street, by=join_by("Street_name" == "StreetName"))
bus_stops <-total_find_missing %>%
  dplyr::select("Street_name", "Planning_Area", "number_of_bus_stops", "average_dist")

```

```{r}
write.csv(bus_stops, "../data/number_of_bus_stops_near_street.csv")

```


```{r}
#cwd
mrt <- read.csv("../Cleaned_Datasets/number_of_mrt_near_street.csv")
bus_stop <- read.csv("../Cleaned_Datasets/number_of_bus_stops_near_street.csv")
```

```{r}

mrt_and_bus_stops <- mrt %>%
  full_join(bus_stop, join_by("Street_name" == "StreetName")) %>%
  mutate(
    number_of_stations = replace_na(number_of_stations, 0),
    average_dist_mrt = replace_na(average_dist_mrt, 300)
  )
  

```


```{r}
max_min_normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

df_normalized <- mrt_and_bus_stops %>%
  mutate(across(where(is.numeric), max_min_normalize))

df_final <- df_normalized %>%
  dplyr::select(c("number_of_stations", "average_dist_mrt", "number_of_bus_stops", "average_dist_bus"))

```



```{r}
pca_model <- PCA(df_final, scale.unit = TRUE, graph = FALSE)

new_variables <- as.data.frame(pca_model$ind$coord)
head(new_variables) 
```
```{r}
library(factoextra)

fviz_eig(pca_model, addlabels = TRUE, ylim = c(0, 100))

```
```{r}
# Get the percentage of variance explained
variance_explained <- pca_model$eig[,2]  # 2nd column = % variance explained
cumulative_variance <- cumsum(variance_explained)

# Print cumulative variance
print(cumulative_variance)

# Find the minimum number of PCs needed to explain 90% variance
min(which(cumulative_variance >= 90))

```

```{r}
pca_loadings <- pca_model$var$coord  # PCA loadings (contributions of original variables)
print(pca_loadings)

```

```{r}
pca_scores <- pca_model$ind$coord  # Individual scores for each observation
weights <- c(0.3651, 0.2452, 0.2335, 0.1512)  # Convert to proportions (they sum to 1)
accessibility_score <- pca_scores %*% weights  

new_df <- cbind(df_normalized, accessibility_score) %>%
  dplyr::select("Street_name", "accessibility_score")

new_df_normalized <- new_df %>%
  mutate(across(where(is.numeric), max_min_normalize))
```

