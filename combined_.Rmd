---
title: "Combined"
author: "YH"
date: "2025-03-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load libraries
```{r libraries}
library(readr)
library(readxl)
library(stringr)
library(lubridate)
library(tidyverse)
library(dplyr)
library(dynlm)
library(sf)
library(geosphere)
library(jsonlite)
library(geosphere)
library(httr)
library(jsonlite)
#library(FactoMineR)
#library(factoextra)
library(geosphere)
library(data.table)
library(factoextra)

```

## Getting Street names and Rental Prices
```{r}
# cleaning rental dataset
q1_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303231245.csv")
q2_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303230811.csv")
q3_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303230853.csv")
q4_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303231354.csv")
# prices are per square meter per month

rental_prices = rbind(q1_rental_og,q2_rental_og,q3_rental_og,q4_rental_og)%>%
  rename("Quarter" = "Reference.Quarter") %>%
  rename_with(~c("price_25%", "price_median","price_75%"), .cols=3:5) %>%
  filter(!if_all(3:5, ~ . == "-"))  %>%
  mutate(Quarter=str_sub(Quarter,-1,-1)) %>%
  mutate(across(3:5, as.numeric))
  
#getting avergage mdeian price over 4 quarters
rental_prices = rental_prices  %>%
  group_by(Street) %>%
  summarise(avg_median_price=mean(price_median, na.rm=TRUE))

#write.csv(rental_prices, "Cleaned_Datasets/rental_prices.csv", row.names = FALSE)

```
## Footfall factors
### Getting Planning Areas and population
```{r}
population <- read_csv("Raw_datasets/respopagesex2024.csv", show_col_types = FALSE)

population_by_area <- population %>% dplyr::select(PA, Pop) %>%
  group_by(PA) %>% 
  summarise(total_pop = sum(Pop)) %>%
  arrange(desc(total_pop)) 

```

### FINDING THE NO OF SCHOOLS IN EACH PLANNING AREA
```{r}
planning_areas <- st_read("Raw_datasets/district_and_planning_area.geojson")
schools <- st_read("Raw_datasets/LTASchoolZone.geojson")

ggplot() +
  geom_sf(data = planning_areas, fill = "lightblue", alpha = 0.5) +
  geom_sf(data = schools, color = "red", size = 2) +
  theme_minimal() +
  ggtitle("Planning Areas and Schools in Singapore")

# Transform to Singapore's standard coordinate system (SVY21, EPSG:3414)
planning_areas <- st_transform(planning_areas, 3414)
schools <- st_transform(schools, 3414)

# Spatial join to count schools in each planning area
school_counts <- planning_areas %>%
  st_join(schools, join = st_contains) %>%  # Join schools inside planning areas
  group_by(Planning_Area = planning_area) %>% 
  summarise(Number_of_Schools = n()) %>%
  ungroup() %>%
  arrange(desc(Number_of_Schools)) 

```
## Passenger Volume at nearest bus stop and MRT station
### Getting Bus Stops with API
```{r}

# API endpoint and API key
api_url <- "http://datamall2.mytransport.sg/ltaodataservice/BusStops"
source("api_keys.R") 
api_key = Sys.getenv("lta_datamall_key")


# Initialize variables
skip <- 0
top <- 50  # Number of records per request
all_bus_stops <- data.frame()


while (TRUE) {
  # Send GET request with pagination parameters
  response <- GET(
    api_url,
    add_headers(AccountKey = api_key),
    query = list(`$skip` = skip, `$top` = top)
  )

  # Check if the request was successful
  if (http_status(response)$category != "Success") {
    print(paste("API request failed with status:", http_status(response)$message))
    break
  }

  # Extract and parse the JSON data
  response_content <- content(response, "text")
  json_data <- fromJSON(response_content)

  # Append the data to the all_bus_stops data frame
  current_bus_stops <- as.data.frame(json_data$value)
  all_bus_stops <- rbind(all_bus_stops, current_bus_stops)

  # Check if there are more records
  if (nrow(current_bus_stops) < top) {
    break  # Exit the loop if no more records are returned
  }

  # Update the skip value for the next request
  skip <- skip + top
}

#Check if there's duplicates
all_bus_stops_cleaned <- distinct(all_bus_stops)

### Save the data to a CSV file ###
#write.csv(all_bus_stops_cleaned, "Cleaned_Datasets/bus_stops.csv", row.names = FALSE)

```



##Malls
### FINDING DISTANCE OF NEAREST MALL 
```{r}
malls <- read.csv("Raw_datasets/shopping_mall_coordinates.csv")
coords <- read.csv("Cleaned_datasets/street_name_planning_area.csv")

# Convert to data.table 
coords_dt <- as.data.table(coords)
malls_dt <- as.data.table(malls)

results_list <- list()  

for (i in 1:nrow(coords_dt)) {
  street_name <- coords_dt$Street_name[i]
  street_lat <- coords_dt$latitude[i]
  street_lon <- coords_dt$longitude[i]
  
  # Vectorized distance calculation for all malls
  distances <- distHaversine(
    matrix(c(street_lon, street_lat), nrow = 1),
    matrix(c(malls_dt$LONGITUDE, malls_dt$LATITUDE), ncol = 2)
  )
  
  # Store results in a list
  results_list[[i]] <- data.frame(
    StreetName = street_name,
    MallName = malls_dt$Mall.Name,
    Distance = distances
  )
}

# Combine results 
results_df_mall <- rbindlist(results_list)


### COMBINE ALL THE DATAFRAMES WITH STREETS AND THE CORRESPONDING LANGITUDE AND LONGITUDE
streets <- read_csv("Cleaned_Datasets/street_name_planning_area.csv")

population_by_area <- population_by_area %>%
  mutate(PA = toupper(PA))

```
##Accessibility Score

## FINDING THE DISTANCE FROM THE STREET TO THE MRT STATIONS 
```{r}
### FINDING THE DISTANCE FROM THE STREET TO THE MRT STATIONS ###
stations <- read_csv("Raw_datasets/stations.csv") %>%
  dplyr::distinct(station_name, .keep_all = TRUE)


#Function to calculate distance
calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}

# Define the distance threshold (in meters)
distance_threshold <- 500000

# Initialize a list to store results
results <- list()

# Loop through each street
for (i in 1:nrow(streets)) {
  street_name <- streets$Street_name[i]
  street_lat <- streets$latitude[i]
  street_lon <- streets$longitude[i]
  
  # Loop through each station
  for (j in 1:nrow(stations)) {
    station_code <- stations$station_code[j]
    station_lat <- stations$lat[j]
    station_lon <- stations$lon[j]
    
    # Calculate the distance
    distance <- calculate_distance(street_lat, street_lon, station_lat, station_lon)
    
    # Check if the distance is below the threshold
    
    results <- rbind(results, data.frame(
    StreetName = street_name,
    StationCode = station_code,
    Distance = distance))
    
  }
}

# Convert the results to a data frame
results_df <- as.data.frame(results)


number_of_mrt <- results_df %>%
  group_by(StreetName) %>%
  filter(Distance <= 500) %>%
  summarise(number_of_stations = n())


dist <- results_df %>%
  group_by(StreetName) %>%
  summarise(dist_to_nearest_mrt=min(Distance))


number_of_mrt_near_street <- number_of_mrt %>% right_join(dist, by = "StreetName")

# Get a dataframe with the street, PA, number of stations that are 'near', and their minimum distance
number_of_mrt_near_street <- left_join(streets,number_of_mrt_near_street, by=join_by("Street_name" == "StreetName"))

number_of_mrt_near_street <-number_of_mrt_near_street %>%
  dplyr::select("Street_name", "Planning_Area", "number_of_stations", "dist_to_nearest_mrt") %>%
  mutate(across(c("number_of_stations"), ~replace_na(.x,0)))

#Export CSV
#write.csv(number_of_mrt_near_street, "Cleaned_Datasets/number_of_mrt_near_street.csv")

```



## Distance Calculation/Formula 
```{r}
calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}
```

## Calculate distance from street to Bus stops 
```{r}
all_bus_stops_cleaned <- read_csv("Cleaned_Datasets/bus_stops.csv")

# Convert to data.table 
coords_dt <- as.data.table(coords)
bus_stops_dt <- as.data.table(distinct(all_bus_stops_cleaned))

results_list <- list()  

for (i in 1:nrow(coords_dt)) {
  street_name <- coords_dt$Street_name[i]
  street_lat <- coords_dt$latitude[i]
  street_lon <- coords_dt$longitude[i]
  
  # Vectorized distance calculation for all bus stops
  distances <- distHaversine(
    matrix(c(street_lon, street_lat), nrow = 1),
    matrix(c(bus_stops_dt$Longitude, bus_stops_dt$Latitude), ncol = 2)
  )
  
  # Store results in a list
  results_list[[i]] <- data.frame(
    StreetName = street_name,
    BusStopCode = bus_stops_dt$BusStopCode,
    Distance = distances
  )
}

# Combine results 
results_df_bus <- rbindlist(results_list)

# Calculate the number of bus stops for each streets that is within the threshold of 250m
number_of_bus_stops <- results_df_bus %>%
  group_by(StreetName) %>%
  filter(Distance <= 250) %>%
  summarise(number_of_bus_stops = n())

# Finding the distance to the nearest bus stop from each street
dist_bus <- results_df_bus %>%
  group_by(StreetName) %>%
  summarise(dist_to_nearest_bus_stop = min(Distance, na.rm = TRUE))

number_of_bus_stops_near_street <- number_of_bus_stops %>% full_join(dist_bus, by = "StreetName")

# Get a dataframe with the street, PA, number of stations that are 'near'
number_of_bus_stops_near_street <- left_join(streets, number_of_bus_stops_near_street, by=join_by("Street_name" == "StreetName")) 

number_of_bus_stops_near_street <-number_of_bus_stops_near_street %>%
  dplyr::select("Street_name", "Planning_Area", "number_of_bus_stops", "dist_to_nearest_bus_stop") %>%
  mutate(across(c("number_of_bus_stops"), ~replace_na(.x, 0)))


```

```{r}
#write.csv(number_of_bus_stops_near_street, "Cleaned_Datasets/number_of_bus_stops_near_street.csv")
```

## Obtaining Tap Out for Stations 
```{r}
# API Key
api_key <- "S4FSEoEgQc2BazhsvqOHjQ=="

# API Endpoint
url <- "http://datamall2.mytransport.sg/ltaodataservice/PV/Train"

# Send Request and Get Response
response <- GET(url, add_headers(AccountKey = api_key))

# Convert JSON Response to R List
data <- fromJSON(content(response, "text"))
csv_url <- data$value[[1]]  # Extract the URL from JSON

#print(paste("Download CSV from:", csv_url))  # Check the link

# Download CSV File
csv_file_train <- "train_passenger_volume.csv"
download.file(csv_url, csv_file_train, mode = "wb")  # Download CSV file


### PASSENGER VOLUMES (TRAIN) ###
stations <- read_csv("Raw_datasets/stations.csv") %>%
  dplyr::select(-c("source", "comment")) %>%
  mutate(station_pattern = paste0("\\b", station_code, "\\b"))

# Read in downloaded CSV file
# For each station, finding what's the total tap in and tap out 
passenger_volume_train <- read_csv(csv_file_train) %>%
  group_by(PT_CODE) %>%
  summarise(total_tap_in_mrt = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE), total_tap_out_mrt = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE)) %>%
  ungroup()

# Fuzzy join to join based on whether station_code is a substring of PT_CODE because some stations are on more than one line
df_train <- regex_left_join(passenger_volume_train, stations, by = c("PT_CODE" = "station_pattern")) %>%
  dplyr::distinct(total_tap_in_mrt, .keep_all = TRUE)

```

## Finding the tap out rate for the nearest MRT station to the street 
```{r}
#################
#Function to calculate distance
calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}

# Define the distance threshold (in meters)
distance_threshold <- 500000

# Initialize a list to store results
results <- list()

# Loop through each street
for (i in 1:nrow(streets)) {
  street_name <- streets$Street_name[i]
  street_lat <- streets$latitude[i]
  street_lon <- streets$longitude[i]
  
  # Loop through each station
  for (j in 1:nrow(stations)) {
    station_code <- stations$station_code[j]
    station_lat <- stations$lat[j]
    station_lon <- stations$lon[j]
    
    # Calculate the distance
    distance <- calculate_distance(street_lat, street_lon, station_lat, station_lon)
    
    # Check if the distance is below the threshold
    
    results <- rbind(results, data.frame(
      StreetName = street_name,
      StationCode = station_code,
      Distance = distance))
    
  }
}

# Convert the results to a data frame
results_df <- as.data.frame(results)

##########################

dist_mrt <- results_df %>%
  group_by(StreetName) %>%
  summarise(dist_to_nearest_mrt=min(Distance), StationCode = StationCode[which.min(Distance)])


# weights = 1/distance
# create a new variable called dist_weighted_PV_bus that is a measure of footfall
expanded_df <- df_train %>%
  separate_rows(PT_CODE, sep = "/") %>%
  distinct()

mrt_code_cood_dist <- left_join(dist_mrt, expanded_df, by = c("StationCode" = "PT_CODE")) %>%
  dplyr::select(-c("station_code", "station_pattern")) %>%
  mutate(dist_weighted_PV_train = (1/dist_to_nearest_mrt) * total_tap_out_mrt)

```

## Obtaining Tap Out rate for bus stops 
```{r}
# Step 1: Set API Key
api_key <- "S4FSEoEgQc2BazhsvqOHjQ=="

# Step 2: Define API Endpoint
url <- "http://datamall2.mytransport.sg/ltaodataservice/PV/Bus"

# Step 3: Send Request and Get Response
response <- GET(url, add_headers(AccountKey = api_key))

# Step 4: Convert JSON Response to R List
data <- fromJSON(content(response, "text"))

# Step 5: Extract CSV Download Link
csv_url <- data$value[[1]]  # Extract the first URL from JSON response

print(paste("Download CSV from:", csv_url))  # Check the link

# Step 6: Download and Save the CSV File
csv_file_bus <- "bus_passenger_volume.csv"  # Change path if needed
download.file(csv_url, csv_file_bus, mode = "wb")

# Step 7: Load CSV into R
bus_data <- read_csv(csv_file_bus) %>%
  group_by(PT_CODE) %>%
  summarise(total_tap_in_bus = sum(TOTAL_TAP_IN_VOLUME, na.rm = TRUE), total_tap_out_bus = sum(TOTAL_TAP_OUT_VOLUME, na.rm = TRUE)) %>%
  ungroup()


all_bus_stops_cleaned <- read_csv("Cleaned_Datasets/bus_stops.csv")

bus_code_cood <- left_join(bus_data, all_bus_stops_cleaned, by = c("PT_CODE" = "BusStopCode"))
```
## Finding the tap out rate for the nearest bus stop to the street 
```{r}
coords_dt <- as.data.table(coords)
bus_stops_dt <- as.data.table(distinct(all_bus_stops_cleaned))

results_list <- list()  

for (i in 1:nrow(coords_dt)) {
  street_name <- coords_dt$Street_name[i]
  street_lat <- coords_dt$latitude[i]
  street_lon <- coords_dt$longitude[i]
  
  # Vectorized distance calculation for all bus stops
  distances <- distHaversine(
    matrix(c(street_lon, street_lat), nrow = 1),
    matrix(c(bus_stops_dt$Longitude, bus_stops_dt$Latitude), ncol = 2)
  )
  
  # Store results in a list
  results_list[[i]] <- data.frame(
    StreetName = street_name,
    BusStopCode = bus_stops_dt$BusStopCode,
    Distance = distances
  )
}

# Combine results 
results_df_bus <- rbindlist(results_list)
#############

# Finding the distance to the nearest bus stop from each street
dist_bus <- results_df_bus %>%
  group_by(StreetName) %>%
  summarise(dist_to_nearest_bus_stop = min(Distance, na.rm = TRUE), BusStopCode = BusStopCode[which.min(Distance)])

# weights = 1/distance
# create a new variable called dist_weighted_PV_bus that is a measure of footfall


bus_code_cood_dist <- left_join(dist_bus, bus_code_cood, by = c("BusStopCode" = "PT_CODE")) %>%
  dplyr::select(-c("RoadName", "Description")) %>%
  mutate(dist_weighted_PV_bus = (1/dist_to_nearest_bus_stop) * total_tap_out_bus)


```

## Preparing Necessary Datasets for PCA for Footfall
```{r}
pop_and_num_schools <- read_csv("Cleaned_Datasets/streets_malls_school_pop.csv")

bus_and_mrt_tap_out <- bus_code_cood_dist %>%
  left_join(mrt_code_cood_dist, join_by("StreetName")) %>%
  left_join(pop_and_num_schools, join_by("StreetName" == "Street_name")) %>%
  dplyr::select(c(dist_weighted_PV_bus, dist_weighted_PV_train, total_pop, Number_of_Schools))

```

## PCA model for footfall and determining the number of variable to choose
```{r}
pca_model_footfall <- PCA(bus_and_mrt_tap_out, scale.unit = TRUE, graph = FALSE)
fviz_eig(pca_model_footfall, addlabels = TRUE, ylim = c(0, 100))
variance_explained <- pca_model_footfall$eig[,2]  # 2nd column = % variance explained

##Choose the first 3 
```
## Obtaining an overall footfall score drom PCA 
```{r}
pca_scores_footfall <- pca_model$ind$coord[,0:3]
weights <- c(0.515, 0.27843,0.205814)  
footfall <- as.matrix(pca_scores) %*% weights  
```


## Maximum - minimum normalisation 
```{r}
max_min_normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

```

## Obtaining footfall scores with normalisation
```{r}
footfall_score <- cbind(pop_and_num_schools, footfall) %>%
  dplyr::select("Street_name", "footfall") %>%
  mutate(across(where(is.numeric), max_min_normalize))
```

## Read in all the cleaned csv 
```{r}
df1 <- read.csv("Cleaned_Datasets/number_of_bus_stops_near_street.csv")
df2 <- read.csv("Cleaned_Datasets/rental_prices.csv")
df3 <- read.csv("Cleaned_Datasets/streets_malls_school_pop.csv") %>%
  dplyr:: select(Street_name, dist_to_nearest_mall, Number_of_Schools, total_pop, longitude, latitude, "Planning_Area")
df4 <- read.csv("Cleaned_Datasets/number_of_mrt_near_street.csv") %>%
  dplyr:: select(Street_name, number_of_stations, dist_to_nearest_mrt)

```

## Performing PCA to obtain relevant accessibility score 
```{r}
mrt <- read.csv("Cleaned_Datasets/number_of_mrt_near_street.csv")
bus_stop <- read.csv("Cleaned_Datasets/number_of_bus_stops_near_street.csv")
diff_in_timing <- read.csv("Cleaned_Datasets/street_by_weighted_diff.csv") %>%
  rename(Street_name = "Street..Destination." )
```

## Combining the different components of PCA for accessibility scores
```{r}
mrt_and_bus_stops <- mrt %>%
  full_join(bus_stop, join_by("Street_name"))  %>%
  full_join(diff_in_timing, join_by("Street_name"))

```

## Normalising the numerical values with min-max normalisation 
```{r}
df_normalized <- mrt_and_bus_stops %>%
  mutate(across(where(is.numeric), max_min_normalize))

df_final <- df_normalized %>%
  dplyr::select(c("number_of_stations", "dist_to_nearest_mrt", "number_of_bus_stops", "dist_to_nearest_bus_stop", "weighted_diff_sum"))

```

## Creating a scree plot with PCA to see number of components to retain 
```{r}

pca_model <- PCA(df_final, scale.unit = TRUE, graph = FALSE)
fviz_eig(pca_model, addlabels = TRUE, ylim = c(0, 100))
variance_explained <- pca_model$eig[,2]  # 2nd column = % variance explained

print(variance_explained)

#After inspecting the variance each component contributes, we have decided to keep 3 components 
```

## Deriving the accessibility score 
```{r}
#Inspect Individual scores for each PC component 
pca_scores <- pca_model$ind$coord[,0:3]

#PC1 score is inversely related, switch the signs 
pca_scores_<- as.data.frame(pca_scores) %>% 
  mutate(`Dim.1`= - `Dim.1`) %>%
  mutate(`Dim.2` = -`Dim.2`)

# Convert to proportions (equate to 1). Weights are given based on the proportion of variation of value it explains. 
weights <- c(0.602286 , 0.202268, 0.194345)  
accessibility_score <- as.matrix(pca_scores_) %*% weights  

new_df <- cbind(df_normalized, accessibility_score) %>%
  dplyr::select("Street_name", "accessibility_score")

accessibility_scores_final <- new_df %>%
  mutate(across(where(is.numeric), max_min_normalize))
```

## Checking for correlation with each component, see whether it makes sense or not.
```{r}
cor_w_numstations = cor(accessibility_scores_final$accessibility_score, df_final$number_of_stations, use = "complete.obs", method = "pearson")
cor_w_numbus_stops= cor(accessibility_scores_final$accessibility_score, df_final$number_of_bus_stops, use = "complete.obs", method = "pearson")
cor_w_mindist_stations = cor(accessibility_scores_final$accessibility_score, df_final$dist_to_nearest_mrt, use = "complete.obs", method = "pearson")
cor_w_mindist_bus_stops = cor(accessibility_scores_final$accessibility_score, df_final$dist_to_nearest_bus_stop, use = "complete.obs", method = "pearson")
cor_w_mindist_time = cor(accessibility_scores_final$accessibility_score, df_final$weighted_diff_sum, use = "complete.obs", method = "pearson")


print(c(cor_w_numstations,cor_w_numbus_stops,cor_w_mindist_stations,cor_w_mindist_bus_stops,cor_w_mindist_time))

```


```{r}
#write.csv(as.data.frame(accessibility_scores_final), "../Cleaned_Datasets/accessibility_scores.csv", row.names = FALSE)
```

```{r}
accessibility_scores <- read.csv("Cleaned_Datasets/accessibility_scores.csv")

df_final <- df3 %>%
  left_join(df2, join_by("Street_name" == "Street")) %>%
  left_join(footfall_score, join_by("Street_name")) %>%
  left_join(accessibility_scores, join_by("Street_name")) 

df_select <- df_final %>%
  dplyr::select(c("footfall", "dist_to_nearest_mall", "avg_median_price", "accessibility_score", "Street_name")) %>%
  mutate(across(where(is.numeric), max_min_normalize))
```


# Our Scoring Model
```{r}
final_score <- 0.379537954*df_select$footfall - 0.2202202202*df_select$dist_to_nearest_mall + 0.2202202202*df_select$accessibility_score -
  0.180418042*df_select$avg_median_price


final_scores_ <- as.data.frame(cbind(final_score, df_select$"Street_name")) %>%
  dplyr::arrange(desc(final_score))


```



```{r}
#Accessibility score 
##Number of bus stops (within 250m)
##Distance of nearest bus stop
##Number of mrt stops (within 500m)
##Distance of nearest mrt stop 

#footfall
##population, schools, passenger vol (weighted by inverse distance)

#final model
##accessibility score
##footfall 
##malls
##rental price


#Average passenger volume per MRT stop 
#Average passenger volume per bus stop

```

```{r}

```


