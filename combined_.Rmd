---
title: "Combined"
author: "YH"
date: "2025-03-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r libraries}
library(readr)
library(readxl)
library(stringr)
library(lubridate)
library(tidyverse)
library(dplyr)
library(dynlm)
library(vars)
library(tseries)
library(forecast)
library(sf)
library(geosphere)
library(jsonlite)
library(geosphere)
library(httr)
library(jsonlite)

```
```{r}
#summary(planning_areas)
schools
```

## Getting Planning Areas 
```{r}
population <- read_csv("Raw_datasets/respopagesex2024.csv", show_col_types = FALSE)

population_by_area <- population %>% dplyr::select(PA, Pop) %>%
  group_by(PA) %>% 
  summarise(total_pop = sum(Pop)) %>%
  arrange(desc(total_pop)) 


### FINDING THE NO OF SCHOOLS IN EACH PLANNING AREA ###
planning_areas <- st_read("Raw_datasets/district_and_planning_area.geojson")
schools <- st_read("Raw_datasets/LTASchoolZone.geojson")

ggplot() +
  geom_sf(data = planning_areas, fill = "lightblue", alpha = 0.5) +
  geom_sf(data = schools, color = "red", size = 2) +
  theme_minimal() +
  ggtitle("Planning Areas and Schools in Singapore")

# Transform to Singapore's standard coordinate system (SVY21, EPSG:3414)
planning_areas <- st_transform(planning_areas, 3414)
schools <- st_transform(schools, 3414)


# Spatial join to count schools in each planning area
school_counts <- planning_areas %>%
  st_join(schools, join = st_contains) %>%  # Join schools inside planning areas
  group_by(Planning_Area = planning_area) %>% 
  summarise(Number_of_Schools = n()) %>%
  ungroup() %>%
  arrange(desc(Number_of_Schools)) 

# ROW IS THE PLANNING AREAS AND COLS IS THE SCHOOL
#distance_matrix <- as.data.frame(st_distance(planning_areas, schools))



### FINDING THE NO OF MALLS IN EACH OF THE PLANNING AREA ###
malls <- read.csv("Raw_datasets/shopping_mall_coordinates.csv")

# Transform the longitude and latitude to geometry?
malls <- malls %>%
  st_as_sf(coords = c("LONGITUDE", "LATITUDE"), crs = 4326) %>%
  st_transform(3414)

# Transform to Singapore's standard coordinate system (SVY21, EPSG:3414)
planning_areas <- st_transform(planning_areas, 3414)

ggplot() +
  geom_sf(data = planning_areas, fill = "lightblue", alpha = 0.5) +
  geom_sf(data = malls, color = "red", size = 2) +
  theme_minimal() +
  ggtitle("Planning Areas and Malls in Singapore")


# Spatial join to count malls in each planning area
mall_counts <- planning_areas %>%
  st_join(malls, join = st_contains) %>%  # Join schools inside planning areas
  group_by(Planning_Area = planning_area) %>% 
  summarise(Number_of_Malls = n()) %>%
  ungroup() %>%
  arrange(desc(Number_of_Malls)) 

# Drop geometry to join them together
mall_counts_nogeom <- st_drop_geometry(mall_counts)
school_counts_nogeom <- st_drop_geometry(school_counts)

combine_dataframe <- left_join(mall_counts_nogeom, school_counts_nogeom, by = "Planning_Area") %>%
  mutate(Planning_Area = toupper(Planning_Area)) 


### COMBINE ALL THE DATAFRAMES WITH STREETS AND THE CORRESPONDING LANGITUDE AND LONGITUDE ###
streets <- read_csv("Cleaned_Datasets/street_name_planning_area.csv")

population_by_area <- population_by_area %>%
  mutate(PA = toupper(PA))

final_dataframe <- streets %>%
  left_join(combine_dataframe, by = "Planning_Area") %>%
  left_join(population_by_area, by = c("Planning_Area" = "PA"))


### EXPORT AS CSV ###
#write.csv(final_dataframe, "Cleaned_Datasets/streets_malls_school_pop.csv", row.names = FALSE)


```

## FINDING THE DISTANCE FROM THE STREET TO THE MRT STATIONS ###

```{r}
### FINDING THE DISTANCE FROM THE STREET TO THE MRT STATIONS ###
stations <- read_csv("Raw_datasets/stations.csv") %>%
  dplyr::distinct(station_name, .keep_all = TRUE)


#Function to calculate distance
calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}

# Define the distance threshold (in meters)
distance_threshold <- 500

# Initialize a list to store results
results <- list()

# Loop through each street
for (i in 1:nrow(streets)) {
  street_name <- streets$Street_name[i]
  street_lat <- streets$latitude[i]
  street_lon <- streets$longitude[i]
  
  # Loop through each bus stop
  for (j in 1:nrow(stations)) {
    station_code <- stations$station_code[j]
    station_lat <- stations$lat[j]
    station_lon <- stations$lon[j]
    
    # Calculate the distance
    distance <- calculate_distance(street_lat, street_lon, station_lat, station_lon)
    
    # Check if the distance is below the threshold
    if (distance <= distance_threshold) {
      results <- rbind(results, data.frame(
        StreetName = street_name,
        StationCode = station_code,
        Distance = distance
      ))
    }
  }
}

# Convert the results to a data frame
results_df <- as.data.frame(results)

# Print the results
print(results_df)

number_of_mrt_near_street <- results_df %>%
  group_by(StreetName) %>%
  summarise(number_of_stations=n(), average_dist_mrt=sum(Distance)/n())

# Get a dataframe with the street, PA, number of stations that are 'near', and their average distance
number_of_mrt_near_street <- left_join(streets,number_of_mrt_near_street, by=join_by("Street_name" == "StreetName"))
number_of_mrt_near_street <-number_of_mrt_near_street %>%
  dplyr::select("Street_name", "Planning_Area", "number_of_stations", "average_dist_mrt")

#Export CSV
#write.csv(number_of_mrt_near_street, "Cleaned_Datasets/number_of_mrt_near_street.csv")


```


## Rental Prices 
```{r}
# cleaning rental dataset
q1_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303231245.csv")
q2_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303230811.csv")
q3_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303230853.csv")
q4_rental_og = read.csv("Raw_datasets/CommercialRentalStatsByStreet20250303231354.csv")
# prices are per square meter per month

rental_prices = rbind(q1_rental_og,q2_rental_og,q3_rental_og,q4_rental_og)%>%
  rename("Quarter" = "Reference.Quarter") %>%
  rename_with(~c("price_25%", "price_median","price_75%"), .cols=3:5) %>%
  filter(!if_all(3:5, ~ . == "-"))  %>%
  mutate(Quarter=str_sub(Quarter,-1,-1)) %>%
  mutate(across(3:5, as.numeric))
  
rental_prices = rental_prices  %>%
  group_by(Street) %>%
  summarise(avg_median_price=mean(price_median, na.rm=TRUE))

#write csv
#write.csv(rental_prices, "Cleaned_Datasets/rental_prices.csv", row.names = FALSE)
  
# read in planning area
street_name_planning_area = read.csv("Cleaned_Datasets/street_name_planning_area.csv")

```



## Getting Bus Stops with API
```{r pressure, echo=FALSE}

# API endpoint and API key
api_url <- "http://datamall2.mytransport.sg/ltaodataservice/BusStops"
api_key <- "oS8RIpj+SBK/tB+Hv5CHVg==" 

# Initialize variables
skip <- 0
top <- 50  # Number of records per request
all_bus_stops <- data.frame()


while (TRUE) {
  # Send GET request with pagination parameters
  response <- GET(
    api_url,
    add_headers(AccountKey = api_key),
    query = list(`$skip` = skip, `$top` = top)
  )
  
  # Check if the request was successful
  if (http_status(response)$category != "Success") {
    print(paste("API request failed with status:", http_status(response)$message))
    break
  }
  
  # Extract and parse the JSON data
  response_content <- content(response, "text")
  json_data <- fromJSON(response_content)
  
  # Append the data to the all_bus_stops data frame
  current_bus_stops <- as.data.frame(json_data$value)
  all_bus_stops <- rbind(all_bus_stops, current_bus_stops)
  
  # Check if there are more records
  if (nrow(current_bus_stops) < top) {
    break  # Exit the loop if no more records are returned
  }
  
  # Update the skip value for the next request
  skip <- skip + top
}

# Print the final data frame
print(all_bus_stops)
all_bus_stops_cleaned <- distinct(all_bus_stops)
# Save the data to a CSV file
#write.csv(all_bus_stops, "Cleaned_Datasets/bus_stops.csv", row.names = FALSE)

```

## Distance Calculation/Formula 
```{r}
coords <- read.csv("Cleaned_datasets/street_name_planning_area.csv")

calculate_distance <- function(lat1, lon1, lat2, lon2) {
  distHaversine(c(lon1, lat1), c(lon2, lat2))
}
```

## Calculate distance from street to Bus stops 

```{r}
# Define the distance threshold (in meters)
distance_threshold <- 500

# Initialize a list to store results
results <- list()

# Loop through each street
for (i in 1:nrow(coords)) {
  street_name <- coords$Street_name[i]
  street_lat <- coords$latitude[i]
  street_lon <- coords$longitude[i]
  
  # Loop through each bus stop
  for (j in 1:nrow(all_bus_stops_cleaned)) {
    bus_stop_code <- all_bus_stops_cleaned$BusStopCode[j]
    bus_stop_lat <- all_bus_stops_cleaned$Latitude[j]
    bus_stop_lon <- all_bus_stops_cleaned$Longitude[j]
    
    # Calculate the distance
    distance <- calculate_distance(street_lat, street_lon, bus_stop_lat, bus_stop_lon)
    
    # Check if the distance is below the threshold
    if (distance <= distance_threshold) {
      results <- rbind(results, data.frame(
        StreetName = street_name,
        BusStopCode = bus_stop_code,
        Distance = distance
      ))
    }
  }
}

# Convert the results to a data frame
results_df <- as.data.frame(results)

# Print the results
print(results_df)
```


```{r}
number_of_bus_stops_near_street <- results_df %>%
  group_by(StreetName) %>%
  summarise(number_of_bus_stops=n(), average_dist_bus=sum(Distance)/n())
```

```{r}
#write.csv(number_of_bus_stops_near_street, "Cleaned_Datasets/number_of_bus_stops_near_street.csv")
```

```{r}
total_find_missing <- left_join(coords,number_of_bus_stops_near_street, by=join_by("Street_name" == "StreetName"))
bus_stops <-total_find_missing %>%
  dplyr::select("Street_name", "Planning_Area", "number_of_bus_stops", "average_dist_bus")
```


```{r}
#write.csv(bus_stops, "Cleaned_Datasets/number_of_bus_stops_near_street.csv")
```

```{r}
df1 <- read.csv("Cleaned_Datasets/number_of_bus_stops_near_street.csv")
df2 <- read.csv("Cleaned_Datasets/rental_prices.csv")
df3 <- read.csv("Cleaned_Datasets/streets_malls_school_pop.csv") %>%
  dplyr:: select(Street_name, Number_of_Malls, Number_of_Schools, total_pop, longitude, latitude, "Planning_Area")
df4 <- read.csv("Cleaned_Datasets/number_of_mrt_near_street.csv") %>%
  dplyr:: select(Street_name, number_of_stations, average_dist_mrt)

```

```{r}
final_df <- df1 %>%
  full_join(df2, by=join_by("StreetName"=="Street"))%>%
  full_join(df3, by = join_by("StreetName" == "Street_name")) %>%
  full_join(df4, by = join_by("StreetName" == "Street_name")) %>%
  rename("Street_name"="StreetName")
```


```{r}
library(FactoMineR)
library(factoextra)

```

```{r}
df_scaled <- final_df %>%
  dplyr::select(-c("Street_name", "Planning_Area", "X", "longitude", "latitude")) %>%
  mutate(number_of_stations = replace(number_of_stations, is.na(number_of_stations), 0)) %>%
  mutate(indicator_mrt = ifelse(is.na(average_dist_mrt), 0, 1)) %>%
  mutate(average_dist_mrt = replace(average_dist_mrt, is.na(average_dist_mrt), 10000))

#df_scaled <- scale(df_scaled)
```

```{r}
max_min_normalize <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

df_normalized <- df_scaled %>%
  mutate(across(where(is.numeric), max_min_normalize))



```


```{r}
accessibility_score <- -0.2*df_normalized$avg_median_price + 0.2*df_normalized$total_pop + 0.15*df_normalized$Number_of_Malls + 0.15*df_normalized$Number_of_Schools + 0.15*df_normalized$number_of_bus_stops - 0.15*df_normalized$indicator_mrt *df_normalized$average_dist_mrt


round(accessibility_score*1000,2)
```





```{r}

pca_model <- PCA(df_scaled, scale.unit = TRUE, graph = FALSE)

# Get variable importance (PCA loadings)
pca_loadings <- pca_model$var$coord

# Compute absolute loadings for PC1 (most important component)
abs_loadings <- abs(pca_loadings[,1])

# Normalize to get weights summing to 1
weights <- abs_loadings / sum(abs_loadings)

# Print weights
print(weights)

```

